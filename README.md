# SignSpeak - Real-time Gesture Recognition & Speech Conversion

SignSpeak is a real-time gesture recognition and text-to-speech conversion system that interprets hand gestures and converts them into spoken words. It utilizes **OpenCV, MediaPipe, and TensorFlow** for hand tracking and deep learning-based recognition.

 Features Implemented So Far
✅ **Real-time Hand Tracking** using OpenCV & MediaPipe  
✅ **Project Setup & Dependencies Installed**  
✅ **Organized Project Structure**  
✅ **Dataset Collection & Preparation Started**  
✅ **Model Training Plan Defined**  

## 📂 Project Structure (So Far)
```
SignSpeak/
│── dataset/            # Gesture images for training
│── models/             # Trained gesture recognition models
│── gui.py              # GUI implementation (to be developed)
│── main.py             # Runs the full program
│── hand_tracking.py    # Handles hand tracking
│── gesture_recognition.py  # CNN model training & prediction
│── tts.py              # Converts text to speech
```

## 🔧 Installation
To set up the project, install the required dependencies:
```bash
pip install opencv-python mediapipe tensorflow numpy pandas matplotlib pyttsx3 googletrans tkinter
```

 Next Steps
- 📷 **Complete Dataset Collection**
- 🎯 **Train Gesture Recognition Model**
- 🗣️ **Implement TTS for Recognized Gestures**
- 🎨 **Build GUI for User Interaction**

Stay tuned for further updates as we enhance SignSpeak with more features and optimizations!
