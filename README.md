# SignSpeak - Real-time Gesture Recognition & Speech Conversion

SignSpeak is a real-time gesture recognition and text-to-speech conversion system that interprets hand gestures and converts them into spoken words. It utilizes **OpenCV, MediaPipe, and TensorFlow** for hand tracking and deep learning-based recognition.

 Features Implemented So Far
âœ… **Real-time Hand Tracking** using OpenCV & MediaPipe  
âœ… **Project Setup & Dependencies Installed**  
âœ… **Organized Project Structure**  
âœ… **Dataset Collection & Preparation Started**  
âœ… **Model Training Plan Defined**  

## ğŸ“‚ Project Structure (So Far)
```
SignSpeak/
â”‚â”€â”€ dataset/            # Gesture images for training
â”‚â”€â”€ models/             # Trained gesture recognition models
â”‚â”€â”€ gui.py              # GUI implementation (to be developed)
â”‚â”€â”€ main.py             # Runs the full program
â”‚â”€â”€ hand_tracking.py    # Handles hand tracking
â”‚â”€â”€ gesture_recognition.py  # CNN model training & prediction
â”‚â”€â”€ tts.py              # Converts text to speech
```

## ğŸ”§ Installation
To set up the project, install the required dependencies:
```bash
pip install opencv-python mediapipe tensorflow numpy pandas matplotlib pyttsx3 googletrans tkinter
```

 Next Steps
- ğŸ“· **Complete Dataset Collection**
- ğŸ¯ **Train Gesture Recognition Model**
- ğŸ—£ï¸ **Implement TTS for Recognized Gestures**
- ğŸ¨ **Build GUI for User Interaction**

Stay tuned for further updates as we enhance SignSpeak with more features and optimizations!
